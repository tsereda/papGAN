apiVersion: batch/v1
kind: Job
metadata:
  name: pap-train-job
spec:
  backoffLimit: 2
  template:
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 100
        fsGroup: 100
      containers:
      - name: pap-processing
        image: gitlab-registry.nrp-nautilus.io/prp/jupyter-stack/prp
        env:
        - name: REPO_PATH
          value: /opt/repo/papGAN
        command:
        - "bash"
        - "-c"
        args:
        - |
          # --- User and Environment Setup ---
          echo "Running as user: $(whoami), UID: $(id -u), GID: $(id -g)"
          # --- Git Repository Setup ---
          echo "Setting up Git repository..."
          cd ${REPO_PATH}
          git pull origin main || echo "Repository already exists, continuing"
          # --- Install dependencies ---
          echo "Installing required dependencies..."
          pip install dominate visdom wandb
          # --- Clone CycleGAN repository ---
          echo "Cloning CycleGAN repository..."
          git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git
          # --- Install CycleGAN requirements ---
          echo "Installing CycleGAN requirements..."
          pip install -r ${REPO_PATH}/pytorch-CycleGAN-and-pix2pix/requirements.txt
          # --- Extract with fast zstd decompression ---
          apt-get update && apt-get install -y zstd
          echo "Extracting preprocessed data..."
          mkdir -p ${REPO_PATH}/cyclegan_dataset_256_split
          if [ -f "/data/cyclegan_processed_data.tar.zst" ]; then
            tar -x -I "zstd -d -T0" -f /data/cyclegan_processed_data.tar.zst -C ${REPO_PATH}
          else
            echo "Preprocessed data file not found, skipping extraction"
          fi
          # --- Run training with reduced batch size to avoid OOM errors ---
          echo "Starting CycleGAN training..."
          cd ${REPO_PATH}
          python3 pytorch-CycleGAN-and-pix2pix/train.py \
            --dataroot cyclegan_dataset_256_split/ \
            --name healthy2unhealthy_cyclegan \
            --model cycle_gan \
            --batch_size 32 \
            --num_threads 8 \
            --gpu_ids 0,1,2,3,4,5,6,7 \
            --n_epochs 100 \
            --n_epochs_decay 35 \
            --display_freq 100 \
            --print_freq 100 \
            --lambda_B 7.5 \
            --lambda_A 7.5
          echo "Training completed successfully."

          echo "Copying generator weights to PVC"
          cp /opt/repo/papGAN/checkpoints/healthy2unhealthy_cyclegan/latest_net_G_A.pth /data/latest_net_G_A.pth
          cp /opt/repo/papGAN/checkpoints/healthy2unhealthy_cyclegan/latest_net_G_A.pth /data/latest_net_G_A.pth
        volumeMounts:
        - name: git-repo
          mountPath: /opt/repo
        - name: pap-data-volume
          mountPath: /data
        - name: dshm
          mountPath: /dev/shm
        resources:
          limits:
            memory: 30Gi
            cpu: "24"
            nvidia.com/gpu: "8"
          requests:
            memory: 25Gi
            cpu: "20"
            nvidia.com/gpu: "8"
      initContainers:
      - name: init-git-repo
        image: alpine/git
        args:
        - clone
        - --single-branch
        - -b
        - main
        - https://github.com/tsereda/papGAN
        - /opt/repo/papGAN
        volumeMounts:
        - name: git-repo
          mountPath: /opt/repo
        resources:
          limits:
            memory: 600Mi
            cpu: 600m
          requests:
            memory: 500Mi
            cpu: 500m            # The specific label for L40 GPUs
      volumes:
      - name: git-repo
        emptyDir: {}
      - name: pap-data-volume
        persistentVolumeClaim:
          claimName: pap-data
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 16Gi
      restartPolicy: Never