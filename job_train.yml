apiVersion: batch/v1
kind: Job
metadata:
  name: pap-end-to-end-job
spec:
  backoffLimit: 0
  template:
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 100
        fsGroup: 100
      containers:
      # --- Main Container for end-to-end pipeline ---
      - name: pap-processing
        image: gitlab-registry.nrp-nautilus.io/prp/jupyter-stack/prp
        env:
        - name: REPO_PATH
          value: /app/papGAN
        - name: VISDOM_SERVER
          value: "http://localhost"
        - name: VISDOM_PORT
          value: "8097"
        - name: WANDB_API_KEY
          valueFrom:
            secretKeyRef:
              name: wandb-credentials  # Replace with your actual secret name
              key: api-key
        command:
        - "bash"
        - "-c"
        args:
        - |
          # --- User and Environment Setup ---
          echo "Running as user: $(whoami), UID: $(id -u), GID: $(id -g)"
          


          # --- Git Repository Setup ---
          echo "Setting up Git repository..."
          cd /app
          git clone --single-branch -b main https://github.com/tsereda/papGAN
          cd ${REPO_PATH}
          
          # --- Install dependencies ---
          echo "Installing required dependencies..."
          pip install wandb dominate visdom wandb pytorch_fid torchmetrics[image] tqdm pillow --no-cache-dir
          # Add to your script
          python -c "import wandb; wandb.login(key='${WANDB_API_KEY}')"

          # --- Clone CycleGAN repository ---
          echo "Cloning CycleGAN repository..."
          git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git
          
          # --- Install CycleGAN requirements ---
          echo "Installing CycleGAN requirements..."
          pip install -r ${REPO_PATH}/pytorch-CycleGAN-and-pix2pix/requirements.txt
          
          # --- Update system packages ---
          apt-get update && apt-get install -y zstd p7zip-full
          
          # --- STEP 1: PREPROCESSING ---
          echo "Extracting preprocessed data..."
          mkdir -p ${REPO_PATH}/cyclegan_dataset_256_split
          echo "Listing data directory:"
          ls -lh /data/
          
          if [ -f "/data/cyclegan_processed_data.tar.zst" ]; then
            echo "Preprocessed data file found, extracting..."
            tar -x -I "zstd -d -T0" -f /data/cyclegan_processed_data.tar.zst -C ${REPO_PATH}
          else
            echo "Preprocessed data file not found, skipping extraction"
            exit 1
          fi
          
          # --- Validate preprocessing ---
          echo "Validating preprocessed data..."
          cd ${REPO_PATH}
          python3 validate_preprocesseddata.py

                    echo "Visdom server configured at: ${VISDOM_SERVER}:${VISDOM_PORT}"

          # Wait for Visdom server to be ready
          echo "Waiting for Visdom server to initialize..."
          for i in {1..30}; do
            if curl -s http://localhost:8097 > /dev/null; then
              echo "Visdom server is ready"
              break
            fi
            echo "Waiting for Visdom server... ($i/30)"
            sleep 2
          done
          
          
          # --- STEP 2: TRAINING ---
          echo "Starting CycleGAN training..."
          cd ${REPO_PATH}
          python3 pytorch-CycleGAN-and-pix2pix/train.py \
            --dataroot cyclegan_dataset_256_split/ \
            --name healthy2unhealthy_cyclegan \
            --model cycle_gan \
            --batch_size 32 \
            --num_threads 16 \
            --n_epochs 5 \
            --n_epochs_decay 1 \
            --display_freq 10 \
            --print_freq 100 \
            --lambda_B 7.5 \
            --lambda_A 7.5 \
            --display_id 1 \
            --display_server "localhost" \
            --display_port "${VISDOM_PORT}" \
            --display_env "cyclegan_pap_training" \
            --use_wandb

          echo "Training completed successfully."

          # --- Save generator weights ---
          echo "Copying generator weights to PVC"
          cp ${REPO_PATH}/checkpoints/healthy2unhealthy_cyclegan/latest_net_G_A.pth /data/latest_net_G_A.pth
          cp ${REPO_PATH}/checkpoints/healthy2unhealthy_cyclegan/latest_net_G_B.pth /data/latest_net_G_B.pth
          
          # --- STEP 3: EVALUATION ---
          echo "Preparing for evaluation..."
          mkdir -p ${REPO_PATH}/checkpoints/unhealthy
          cp /data/latest_net_G_A.pth ${REPO_PATH}/checkpoints/unhealthy/latest_net_G_A.pth
          cp /data/latest_net_G_B.pth ${REPO_PATH}/checkpoints/unhealthy/latest_net_G_B.pth
          
          echo "Running evaluation AtoB ..."
          cd ${REPO_PATH}
          python pytorch-CycleGAN-and-pix2pix/test.py \
            --dataroot ./cyclegan_dataset_256_split/test_healthy \
            --name unhealthy \
            --model test \
            --no_dropout \
            --num_test 1162 \
            --results_dir ./results_20k \
            --direction AtoB
          
          python3 restruture_cyclegan_output.py --input_folder results_20k/unhealthy/test_latest/images/
          
          python fid.py \
            --real-healthy cyclegan_dataset_256_split/valA \
            --real-unhealthy cyclegan_dataset_256_split/valB \
            --generated results_20k/unhealthy/test_latest/generated \
            --device cuda \
            --batch-size 64

          echo "Running evaluation... BtoA"
          cd ${REPO_PATH}
          python pytorch-CycleGAN-and-pix2pix/test.py \
            --dataroot ./cyclegan_dataset_256_split/test_healthy \
            --name unhealthy \
            --model test \
            --no_dropout \
            --num_test 1162 \
            --results_dir ./results_20k \
            --direction BtoA
          
          python3 restruture_cyclegan_output.py --input_folder results_20k/unhealthy/test_latest/images/
          
          python fid.py \
            --real-healthy cyclegan_dataset_256_split/valA \
            --real-unhealthy cyclegan_dataset_256_split/valB \
            --generated results_20k/unhealthy/test_latest/generated \
            --device cuda \
            --batch-size 64
          
          # --- Save evaluation results ---
          cp fid_results.txt /data/fid_results.txt
          
          echo "End-to-end pipeline completed successfully!"
        volumeMounts:
        - name: git-repo
          mountPath: /app
        - name: pap-data-volume
          mountPath: /data
        - name: dshm
          mountPath: /dev/shm
        resources:
          limits:
            memory: 30Gi
            cpu: "24"
            nvidia.com/a100: "1"
          requests:
            memory: 25Gi
            cpu: "20"
            nvidia.com/a100: "1"

      # --- Visdom Server Sidecar Container ---
      - name: visdom-server
        image: python:3.9-slim
        command: ["bash", "-c"]
        securityContext:
          runAsUser: 0
        args:
          - |
            pip install visdom
            python -m visdom.server -port 8097
        ports:
        - containerPort: 8097
          name: visdom-ui
        resources:
          limits:
            memory: 600Mi
            cpu: 600m
          requests:
            memory: 500Mi
            cpu: "500m"
            
      volumes:
      - name: git-repo
        emptyDir: {}
      - name: pap-data-volume
        persistentVolumeClaim:
          claimName: pap-data
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 20Gi
      restartPolicy: Never